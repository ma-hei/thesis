\chapter{Experiments}

\input{Datasets.tex}

\section{Experimental Settings}

\subsection{Binary vs. Continuous Prediction}
\label{bincont}
For the evaluation of the model, a performance evaluation for the classification of drug-target pairs into binding or non-binding was also included, using the metrics \textit{AUC} and \textit{AUPR}. Therefore, the datasets where binarized by applying thresholds as it was done in \cite{pahikkala2014toward}. The $MF+CCRF$ model can only predict continuous values, therefore the threshold was applied on the true values after the prediction step, in order to compute $AUC$ and $AUPR$. In the \textit{Davis} and \textit{Metz} datasets, the higher the $pK_d$ or $pK_i$ value, the higher the binding affinity between a drug and a target. For the \textit{Metz} dataset, the same threshold of $pK_i\geq7.6$ was used as suggested in \cite{pahikkala2014toward} to assign a label of $1$ meaning binding and $0$ meaning non-binding. For the \textit{Davis} dataset, a threshold of $pK_d\geq7.0$ which is a bit less stringent than the threshold that is suggested in \cite{pahikkala2014toward} is used. In the original \textit{KIBA} dataset, the lower the \textit{KIBA}-score, the higher the binding affinity and \cite{tang2014making} suggests a threshold of \textit{KIBA}-score$\leq3$ to binarize the dataset. In an additional preprocessing step, the \textit{KIBA}-scores were transformed by taking the negative of each value and adding the minimum to all values in order to obtain a threshold where all values \textit{above} the threshold are classified as binding. The \textit{KIBA} threshold of $3$ in the un-transformed dataset then becomes $12.1$ in the transformed \textit{KIBA} dataset. 

It is noteworthy, that when the classification metrics $AUC$ and $AUPR$ are applied, $KronRLS$ learns and predicts binary labels, meaning that the datasets are binarized according to the cutoff thresholds before the training step. The $MF+CCRF$ method in contrast, only predicts continuous values and the cutoff threshold is applied after the prediction step to calculate the $AUC$ and $AUPR$. One can argue, that given two models $A$ and $B$, where $A$ learns to predict continuous values and model $B$ learns to predict binary values, and the performance of model $A$ in terms of $AUC$ and $AUPR$ is as good as the performance of model $B$, then model $A$ is advantageous because it does not need to be retrained (as model $B$) when the cutoff threshold for the dataset is changed.

\subsection{Performance Evaluation}
The model is evaluated using 5 fold cross-validation. In this procedure, the given values in the datasets are randomly partitioned into 5 subsets of equal size. Each subset is in turn used as validation data to test the method that was trained on the remaining 4 subsets. Both, the \textit{MF+CCRF} model and the comparison model $KronRLS$ can use as input either only one of the similarity metrics or both (in addition to the training matrix with the observed binding affinities). When $KronRLS$ gets as input only one of the similarity matrices for example only the drug similarity, it automatically generates a similarity kernel for the targets, where each target is only similar to itself, meaning the identity matrix is imputed for the targets (and vice-versa, when only the target-similarity is given, the identity matrix is used for the drugs). For each dataset, for each performance metric and for each method ($KronRLS$ and \textit{MF+CCRF}), we get 3 evaluation scores that can be compared among the two methods as illustrated in. For the \textit{MF+CCRF} model a fourth evaluation score is listed in the results section, which is the performance of using no similarity information, resulting in the prediction of only $MF$. The used performance metrics are described in the following sections. Figure \ref{fig:evaluation_tables} explains how to read the tables, listing the performance scores

\begin{figure}
\begin{center}
\includegraphics[scale=0.65]{evaluation_descr.png}
\end{center}
\caption[Description of evaluation tables]{\large{Description of the evaluation tables. 2D refers to the drug similarity (the drug similarity is based on the 2-dimensional structure of the compounds as described above). SW refers to the target similarity and stands for Smith-Waterman as described in the Dataset section. $\delta$ is used in the row/column where the drug/target similarity is not used.}}
\label{fig:evaluation_tables}
\end{figure}

\subsubsection{Evaluation Metrics}
As suggested in \cite{pahikkala2014toward}, the concordance index ($CI$) can be used as an evaluation metric for the prediction accuracy as it takes into account that the interaction affinities behind drug-target interactions are continuous values rather than binary ones. The intuition behind the $CI$ is as follows: the $CI$ over a set of paired data is the probability that the predictions for two randomly drawn drug-target pairs with different label values are in the correct order, meaning that the prediction $f_i$ for the larger affinity $y_i$ is larger than the prediction $f_j$ for the smaller affinity value $y_j$:

\begin{equation}
CI = \frac{1}{Z} \sum\limits_{y_i>y_j}h(f_i-f_j)
\end{equation}

where $Z$ is a normalization constant that equals the number of data pairs with different label values, and $h(u)$ is the step function returning $1.0$, $0.5$ and $0.0$ for $u>0$, $u=0$ and $u<0$ respectively. The $CI$ ranges between $0.5$ and $1.0$, where $0.5$ corresponds to a random predictor and $1.0$ corresponds to perfect prediction accuracy \cite{pahikkala2014toward}. 

As mentioned above, the datasets were also binarized according to cut-off thresholds to evalute the performance on the classification task. In case of binary interaction labels, the $CI$ becomes equal to the commonly used Area Under the Receiver Operating Characteristic Curve (AUC) metric \cite{pahikkala2014toward}:

\begin{equation}
AUC = \frac{1}{m_+m_-}\sum\limits_{y_i=1,y_j=-1}h(f_i-f_j)
\end{equation}

where $m_+$ and $m_-$ are the numbers of drug-target pairs belonging to the positive and negative classes. For the binary classification task, the performance was also evaluated using the Area Under the Precision-Recall curve (AUPR), which has been used in most of the previous studies on drug-target interaction prediction.


